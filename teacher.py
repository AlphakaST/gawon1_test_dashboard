from __future__ import annotations
import json
from typing import List, Dict, Any, Tuple, Optional, Set

import streamlit as st
import pandas as pd
from sqlalchemy import text, exc

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="êµì‚¬ìš© ëŒ€ì‹œë³´ë“œ â€” DAT1Â·2Â·3 í†µí•©", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š êµì‚¬ìš© ëŒ€ì‹œë³´ë“œ â€” DAT1Â·DAT2Â·DAT3 í†µí•©")
st.caption("í•™ìƒ ì œì¶œ ë‚´ì—­ì„ ê²€ìƒ‰/ì—´ëŒí•˜ê³  CSVë¡œ ë‚´ë ¤ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë©€í‹° ìŠ¤í‚¤ë§ˆÂ·ë¬¸í•­ ìë™ ê°ì§€)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ì—°ê²°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    # st.connectionì€ .streamlit/secrets.toml ë˜ëŠ” Streamlit Shareì˜ Secrets ì„¤ì •ì„ ìë™ìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤.
    # secretsì— user ëŒ€ì‹  username ìœ¼ë¡œ í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    conn = st.connection("mysql", type="sql")
    conn.query("SELECT 1")
    DB_STATUS = "ONLINE"
except Exception as e:
    conn = None
    DB_STATUS = f"OFFLINE: {e}"

st.info(f"DB ìƒíƒœ: {DB_STATUS}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸: ìŠ¤í‚¤ë§ˆ/í…Œì´ë¸”/ì»¬ëŸ¼ íƒì§€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False, ttl=60)
def get_current_schema() -> str:
    """st.secretsì— ëª…ì‹œëœ ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        return st.secrets.connections.mysql.database
    except Exception:
        return "pr"

@st.cache_data(show_spinner=False, ttl=60)
def get_table_columns(schema: str, table: str) -> Set[str]:
    """íŠ¹ì • í…Œì´ë¸”ì˜ ëª¨ë“  ì»¬ëŸ¼ ì´ë¦„ì„ ì†Œë¬¸ìë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not conn: return set()
    try:
        query = "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA=%s AND TABLE_NAME=%s"
        df_cols = conn.query(query, params=(schema, table), ttl=60)
        return {str(r[0]).lower() for r in df_cols.itertuples(index=False, name=None)}
    except (exc.SQLAlchemyError, KeyError):
        return set()

@st.cache_data(show_spinner=False, ttl=60)
def list_problem_tables() -> List[Tuple[str, str]]:
    """SHOW TABLESë¥¼ ì‚¬ìš©í•˜ì—¬ DAT í…Œì´ë¸” ëª©ë¡ì„ ì•ˆì •ì ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤. (ìˆ˜ì •ëœ ë²„ì „)"""
    if not conn:
        return [('pr', "DAT2")]

    try:
        schema_to_check = get_current_schema()
        
        # SQLì˜ LIKE ëŒ€ì‹  Pythonì—ì„œ í•„í„°ë§í•˜ì—¬ ì•ˆì •ì„± í–¥ìƒ
        query = f"SHOW TABLES FROM `{schema_to_check}`"
        df_all_tables = conn.query(query, ttl=60)

        if df_all_tables.empty:
            return [('pr', "DAT2")]

        all_table_names = df_all_tables.iloc[:, 0].tolist()
        dat_table_names = [name for name in all_table_names if name.upper().startswith('DAT')]

        if not dat_table_names:
            return [('pr', 'DAT2')]
        
        valid_pairs = []
        for table in dat_table_names:
            cols = get_table_columns(schema_to_check, table)
            if 'id' in cols:
                valid_pairs.append((schema_to_check, table))
        
        if not valid_pairs:
             return [('pr', "DAT2")]

        def keyfn(p: Tuple[str, str]):
            _, t = p
            pri = 0 if t.upper() == "DAT3" else 1 if t.upper() == "DAT2" else 2 if t.upper() == "DAT1" else 3
            return (pri, p[0], t)
        valid_pairs.sort(key=keyfn)
        return valid_pairs

    except (exc.SQLAlchemyError, KeyError, IndexError):
        return [('pr', "DAT2")]


@st.cache_data(show_spinner=False, ttl=60)
def detect_question_count(schema: str, table: str, max_q: int = 4) -> int:
    """í…Œì´ë¸”ì˜ ì»¬ëŸ¼ì„ ìŠ¤ìº”í•˜ì—¬ ë¬¸í•­ ìˆ˜(answerN/feedbackN ìŒ)ë¥¼ ê°ì§€í•©ë‹ˆë‹¤. 0ì„ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."""
    cols = get_table_columns(schema, table)
    count = 0
    for n in range(1, max_q + 1):
        if f"answer{n}" in cols and f"feedback{n}" in cols:
            count = n
        else:
            break
    return count

@st.cache_data(show_spinner=True, ttl=30)
def fetch_rows(schema: str, table: str, nq: int, keyword: str = "", limit: int = 500) -> List[Dict[str, Any]]:
    if not conn: return []

    all_cols = get_table_columns(schema, table)
    select_list: List[str] = ["id"]
    if "time" in all_cols: select_list.append("time")
    if "opinion1" in all_cols: select_list.append("opinion1")
    for i in range(1, nq + 1):
        if f"answer{i}" in all_cols: select_list.append(f"answer{i}")
        if f"feedback{i}" in all_cols: select_list.append(f"feedback{i}")

    q = f"SELECT {', '.join(select_list)} FROM `{schema}`.`{table}`"
    params: Dict[str, Any] = {"limit": int(limit)}
    where_parts: List[str] = []

    if keyword:
        like_keyword = f"%{keyword}%"
        params["keyword"] = like_keyword
        if "id" in all_cols: where_parts.append("id LIKE :keyword")
        if "opinion1" in all_cols: where_parts.append("opinion1 LIKE :keyword")
        for i in range(1, nq + 1):
            if f"answer{i}" in all_cols: where_parts.append(f"answer{i} LIKE :keyword")
            if f"feedback{i}" in all_cols: where_parts.append(f"feedback{i} LIKE :keyword")

    if where_parts:
        q += " WHERE " + " OR ".join(where_parts)

    q += f" ORDER BY {'time DESC' if 'time' in all_cols else 'id DESC'} LIMIT :limit"

    try:
        df_rows = conn.query(q, params=params, ttl=30)
        return df_rows.to_dict("records")
    except (exc.SQLAlchemyError, KeyError) as e:
        st.error(f"[DB] ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ê°€ê³µ (JSON í”¼ë“œë°± íŒŒì‹±)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _json_parse(txt: str) -> Optional[Dict[str, Any]]:
    if not txt: return None
    try: return json.loads(txt)
    except Exception: return None

def parse_feedback_generic(text: str, qidx: int, table_name: str = "") -> Dict[str, Any]:
    res = {"score": None, "max": None, "level": None, "feedback": "", "detected": {}, "reason": ""}
    if not text: return res
    data = _json_parse(text)
    if not isinstance(data, dict):
        res["reason"] = "JSON íŒŒì‹± ì‹¤íŒ¨"; res["feedback"] = (text or "")[:500]
        return res
    res["feedback"] = data.get("feedback", "")
    res["detected"] = data.get("detected", {})
    if "score" in data or "max" in data:
        res["score"] = data.get("score"); res["max"] = data.get("max")
    if "level" in data:
        lv = str(data.get("level") or "").upper()
        res["level"] = lv if lv in {"A","B","C","D"} else None
    if "reason" in data and isinstance(data.get("reason"), str):
        res["reason"] = data.get("reason")
    if table_name.upper() == "DAT2":
        flags = {}
        if qidx == 1: flags = {"ì‘ê³ /ì–¼ìŒ": bool(res["detected"].get("freezing")), "ì—´ ë°©ì¶œ(ì‘ê³ ì—´)": bool(res["detected"].get("heat_release"))}
        elif qidx == 2: flags = {"ê³µí†µ: ì—´ í¡ìˆ˜": bool(res["detected"].get("heat_absorb_common")), "ì°¨ì´: ìŠ¹í™”": bool(res["detected"].get("sublimation")), "ì°¨ì´: ìœµí•´": bool(res["detected"].get("fusion"))}
        else: flags = {"ã‰  ì ì—´/ìƒë³€í™” ì—ë„ˆì§€": bool(res["detected"].get("phase_change_energy")),"ã‰¡ ë°œí™”ì /ì—°ì†Œ ìœ„í—˜": bool(res["detected"].get("ignition_point"))}
        res["detected"] = flags
    return res

def to_dataframe(rows: List[Dict[str, Any]], nq: int, table_name: str) -> pd.DataFrame:
    records = []
    for r in rows:
        row: Dict[str, Any] = {
            "ì œì¶œì‹œê°": r.get("time"),
            "í•™ë²ˆ": r.get("id"),
            "ì˜ê²¬(ìš”ì•½)": (r.get("opinion1") or "")[:120] if "opinion1" in r else "",
        }
        total, total_max, has_any_score = 0, 0, False
        for i in range(1, nq + 1):
            pf = parse_feedback_generic(r.get(f"feedback{i}") or "", i, table_name)
            row[f"ì ìˆ˜{i}"] = pf["score"]; row[f"ë§Œì {i}"] = pf["max"]
            if pf["score"] is not None:
                has_any_score = True
                try:
                    total += int(pf["score"])
                    total_max += int(pf["max"]) if pf["max"] is not None else 0
                except (ValueError, TypeError): pass
            row[f"ì„±ì·¨{i}"] = pf["level"]
            row[f"í”¼ë“œë°±{i}(ìš”ì•½)"] = (pf["feedback"] or "")[:120]
            row[f"_answer{i}"] = r.get(f"answer{i}", "")
            row[f"_feedback{i}"] = r.get(f"feedback{i}", "")
            row[f"_reason{i}"] = pf.get("reason", "")
            row[f"_flags{i}"] = pf.get("detected", {})
        row["ì´ì "] = total if has_any_score else None
        row["ì´ì _ë§Œì "] = total_max if (has_any_score and total_max) else None
        records.append(row)

    df = pd.DataFrame.from_records(records)
    if not df.empty and "ì œì¶œì‹œê°" in df.columns:
        df.sort_values(by="ì œì¶œì‹œê°", ascending=False, inplace=True, ignore_index=True)
    elif not df.empty and "í•™ë²ˆ" in df.columns:
        df.sort_values(by="í•™ë²ˆ", ascending=False, inplace=True, ignore_index=True)
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI â€” ì‚¬ì´ë“œë°”(í…Œì´ë¸”/ê²€ìƒ‰/í‘œì‹œê°œìˆ˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.subheader("ğŸ—‚ï¸ ë°ì´í„° ì†ŒìŠ¤ & ì¡°íšŒ ì˜µì…˜")
    tables = list_problem_tables()
    labels = [f"{sch}.{tbl}" for sch, tbl in tables]
    def default_index() -> int:
        for pref in ("DAT3", "DAT2", "DAT1"):
            for i, (_, t) in enumerate(tables):
                if t.upper() == pref: return i
        return 0
    idx = st.selectbox("ë°ì´í„° ì†ŒìŠ¤(ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸”)", range(len(labels)), format_func=lambda i: labels[i], index=min(default_index(), len(labels)-1))
    
    sel_schema, sel_table = tables[idx] if tables else ("pr", "DAT2")
        
    nq = detect_question_count(sel_schema, sel_table)
    st.caption(f"ì„ íƒ: **{sel_schema}.{sel_table}** Â· ìë™ ê°ì§€ ë¬¸í•­ ìˆ˜: **{nq}**")

    kw = st.text_input("í•™ë²ˆ/í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="ì˜ˆ: 10130 ë˜ëŠ” 'ìŠ¹í™”'")
    limit = st.number_input("í‘œì‹œ ê°œìˆ˜(ìµœëŒ€ 2000)", 10, 2000, 500, 10)
    if st.button("ìƒˆë¡œê³ ì¹¨"): st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë³¸ë¬¸ â€” í‘œ/ìƒì„¸/ë‹¤ìš´ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
rows = fetch_rows(schema=sel_schema, table=sel_table, nq=nq, keyword=kw.strip(), limit=int(limit))
df = to_dataframe(rows, nq, sel_table)

# [ìˆ˜ì •] ë°ì´í„° ê±´ìˆ˜ í‘œì‹œ ë¶€ë¶„ì— (ìµœëŒ€ í‘œì‹œ ê±´ìˆ˜) ì•ˆë‚´ ì¶”ê°€
st.markdown(f"**ì´ {len(df)}ê±´**ì˜ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤. (ìµœëŒ€ **{limit}**ê±´ê¹Œì§€ í‘œì‹œ)")


main_cols: List[str] = [c for c in ["ì œì¶œì‹œê°", "í•™ë²ˆ", "ì´ì ", "ì´ì _ë§Œì "] if c in df.columns]
for i in range(1, nq + 1):
    for c in (f"ì ìˆ˜{i}", f"ë§Œì {i}", f"ì„±ì·¨{i}"):
        if c in df.columns and not df[c].isnull().all():
             main_cols.append(c)
if "ì˜ê²¬(ìš”ì•½)" in df.columns and df["ì˜ê²¬(ìš”ì•½)"].str.strip().any():
    main_cols.append("ì˜ê²¬(ìš”ì•½)")

st.dataframe(df[main_cols] if not df.empty else pd.DataFrame(columns=main_cols), use_container_width=True, height=480)

st.divider()
st.subheader("ğŸ§¾ ìƒì„¸ ë³´ê¸°(í•™ë²ˆ ì…ë ¥)")
qid = st.text_input("í•™ë²ˆ ì…ë ¥", placeholder="ì˜ˆ: 10130", key="detail_id")
if qid:
    if df.empty or "í•™ë²ˆ" not in df.columns:
        st.info("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ì–´ í•™ë²ˆì„ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        sub = df[df["í•™ë²ˆ"].astype(str) == qid.strip()]
        if sub.empty:
            st.info("í•´ë‹¹ í•™ë²ˆì˜ ì œì¶œ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            row = sub.iloc[0]
            if nq > 0:
                tab_names = [f"ë¬¸í•­ {i}" for i in range(1, nq + 1)]
                if nq == 4: tab_names = ["ë¬¸í•­ 1", "ë¬¸í•­ 2-1", "ë¬¸í•­ 2-2", "ë¬¸í•­ 3"]
                tabs = st.tabs(tab_names)
                for i, tb in enumerate(tabs, start=1):
                    with tb:
                        c1, c2 = st.columns(2)
                        with c1:
                            if reason := row.get(f"_reason{i}", ""):
                                st.markdown("**ì±„ì  ê·¼ê±°**"); st.write(reason)
                            st.markdown("**í”¼ë“œë°±(ì „ë¬¸)**")
                            try:
                                raw_fb = row.get(f"_feedback{i}", "{}")
                                raw = json.loads(raw_fb if raw_fb and raw_fb.strip() else "{}")
                                st.write(raw.get("feedback", ""))
                                if lv := raw.get("level"): st.caption(f"ì„±ì·¨ìˆ˜ì¤€: {lv}")
                            except Exception:
                                st.write(row.get(f"í”¼ë“œë°±{i}(ìš”ì•½)", ""))
                        with c2:
                            st.markdown("**í•™ìƒ ë‹µì•ˆ(ì „ë¬¸)**"); st.write(row.get(f"_answer{i}", ""))
                            st.markdown("**ì¡°ê±´ ì¶©ì¡±(íƒì§€)**")
                            if flags := row.get(f"_flags{i}"):
                                for k, v in flags.items():
                                    st.write(f"{k}: {'âœ…' if isinstance(v, bool) and v else 'âŒ' if isinstance(v, bool) else v}")
                            else:
                                st.write("-")
            else:
                st.info("ì´ í…Œì´ë¸”ì—ëŠ” ìƒì„¸ ë¶„ì„í•  ë¬¸í•­(ë‹µì•ˆ/í”¼ë“œë°±)ì´ ì—†ìŠµë‹ˆë‹¤.")

            if "ì˜ê²¬(ìš”ì•½)" in row and pd.notna(row["ì˜ê²¬(ìš”ì•½)"]) and row["ì˜ê²¬(ìš”ì•½)"].strip():
                st.markdown("**í•™ìƒ ì˜ê²¬(ì „ë¬¸)**"); st.write(row.get("ì˜ê²¬(ìš”ì•½)"))

st.divider()
st.subheader("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ")
if not df.empty:
    csv_df = df[[c for c in df.columns if not c.startswith("_")]].copy()
    st.download_button("CSVë¡œ ì €ì¥í•˜ê¸°", csv_df.to_csv(index=False).encode("utf-8-sig"), f"{sel_schema}.{sel_table}_dashboard.csv", "text/csv")
else:
    st.info("ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

