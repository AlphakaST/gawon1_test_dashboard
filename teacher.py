# teacher_dashboard_fixed.py â€” DAT1Â·2Â·3 í†µí•© ëŒ€ì‹œë³´ë“œ (ì—°ê²° ë¬¸ì œ í•´ê²°)
# -*- coding: utf-8 -*-
"""
ê¸°ëŠ¥ ìš”ì•½ (ê¸°ì¡´ê³¼ ë™ì¼)
- í•˜ë‚˜ì˜ ëŒ€ì‹œë³´ë“œì—ì„œ DAT1, DAT2, DAT3 í…Œì´ë¸”ì„ ëª¨ë‘ ì¡°íšŒ.
- answerN/feedbackN ì—´ì„ ìë™ íƒì§€í•˜ì—¬ ë¬¸í•­ ìˆ˜ ìë™ ê°ì§€.
- DAT1/2(ì ìˆ˜í˜•)ì™€ DAT3(ì„±ì·¨ìˆ˜ì¤€ Aâ€“D) JSONì„ ëª¨ë‘ íŒŒì‹±í•˜ì—¬ í‘œ/ìƒì„¸ íƒ­ ì œê³µ.
- í‚¤ì›Œë“œ ê²€ìƒ‰, CSV ë‹¤ìš´ë¡œë“œ, ìƒì„¸ í•™ë²ˆ ë³´ê¸°.

ìˆ˜ì • ì‚¬í•­
- DB ì—°ê²° ë°©ì‹ì„ Streamlit Cloudì— ìµœì í™”ëœ `st.connection`ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì—°ê²° ì˜¤ë¥˜ í•´ê²°.
- DB ì¡°íšŒ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ `st.connection`ì˜ `conn.query()` ë©”ì†Œë“œì— ë§ê²Œ ì¬ì‘ì„±.
- SQL ì¸ì ì…˜ ë°©ì§€ë¥¼ ìœ„í•´ íŒŒë¼ë¯¸í„° ë°”ì¸ë”© ë°©ì‹ì„ SQLAlchemy ìŠ¤íƒ€ì¼(:param)ë¡œ í†µì¼.
"""
from __future__ import annotations
import json
from typing import List, Dict, Any, Tuple, Optional, Set

import streamlit as st
import pandas as pd
# --------------------------------------------------------------------------
# ìˆ˜ì • 1: SQLAlchemyì˜ text í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸í•˜ê³  mysql.connectorëŠ” ì œê±°í•©ë‹ˆë‹¤.
# --------------------------------------------------------------------------
from sqlalchemy import text, exc

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜ì´ì§€ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="êµì‚¬ìš© ëŒ€ì‹œë³´ë“œ â€” DAT1Â·2Â·3 í†µí•©", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š êµì‚¬ìš© ëŒ€ì‹œë³´ë“œ â€” DAT1Â·DAT2Â·DAT3 í†µí•©")
st.caption("í•™ìƒ ì œì¶œ ë‚´ì—­ì„ ê²€ìƒ‰/ì—´ëŒí•˜ê³  CSVë¡œ ë‚´ë ¤ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë©€í‹° ìŠ¤í‚¤ë§ˆÂ·ë¬¸í•­ ìë™ ê°ì§€)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìˆ˜ì • 2: DB ì—°ê²° ë°©ì‹ì„ st.connectionìœ¼ë¡œ ë³€ê²½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    db_creds = st.secrets.connections.mysql
    conn = st.connection(
        "mysql", type="sql", dialect="mysql",
        host=db_creds.host, port=db_creds.port, database=db_creds.database,
        username=db_creds.user, password=db_creds.password
    )
    conn.query("SELECT 1") # ì—°ê²° í…ŒìŠ¤íŠ¸
    DB_STATUS = "ONLINE"
except Exception as e:
    conn = None
    DB_STATUS = f"OFFLINE: {e}"
st.info(f"DB ìƒíƒœ: {DB_STATUS}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìˆ˜ì • 3: ëª¨ë“  DB ì¡°íšŒ í•¨ìˆ˜ë¥¼ conn.query() ê¸°ë°˜ìœ¼ë¡œ ì¬ì‘ì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False, ttl=60)
def get_current_schema() -> str:
    if not conn: return ""
    try:
        df = conn.query("SELECT DATABASE()")
        return df.iloc[0, 0] if not df.empty else ""
    except exc.SQLAlchemyError:
        return ""

@st.cache_data(show_spinner=False, ttl=60)
def schema_exists(schema: str) -> bool:
    if not conn: return False
    try:
        df = conn.query("SELECT COUNT(*) FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME=:schema", params={"schema": schema})
        return (df.iloc[0,0] > 0) if not df.empty else False
    except exc.SQLAlchemyError:
        return False

@st.cache_data(show_spinner=False, ttl=60)
def get_table_columns(schema: str, table: str) -> Set[str]:
    if not conn: return set()
    try:
        df = conn.query(
            "SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA=:schema AND TABLE_NAME=:table",
            params={"schema": schema, "table": table}
        )
        return {r.lower() for r in df['COLUMN_NAME']}
    except (exc.SQLAlchemyError, KeyError):
        return set()

@st.cache_data(show_spinner=False, ttl=60)
def list_problem_tables() -> List[Tuple[str, str]]:
    if not conn: return [(get_current_schema(), "DAT2")] # ê¸°ë³¸ê°’
    try:
        current = get_current_schema()
        schemas_to_check = [s for s in {current, "pr"} if s and schema_exists(s)]
        if not schemas_to_check: return [(current, "DAT2")]

        # SQLAlchemyëŠ” IN ì ˆì— ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë°”ì¸ë”©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        sql = """
            SELECT TABLE_SCHEMA, TABLE_NAME FROM INFORMATION_SCHEMA.COLUMNS
            WHERE TABLE_SCHEMA IN :schemas AND COLUMN_NAME IN ('id','answer1','feedback1')
            GROUP BY TABLE_SCHEMA, TABLE_NAME HAVING COUNT(DISTINCT COLUMN_NAME)=3
        """
        df = conn.query(sql, params={"schemas": schemas_to_check})
        pairs = list(zip(df['TABLE_SCHEMA'], df['TABLE_NAME']))

        def keyfn(p: Tuple[str,str]):
            _, t = p
            pri = 0 if t.upper()=="DAT3" else 1 if t.upper()=="DAT2" else 2 if t.upper()=="DAT1" else 3
            return (pri, p[0], t)
        pairs.sort(key=keyfn)
        return pairs or [(current, "DAT2")]
    except (exc.SQLAlchemyError, KeyError):
        return [(get_current_schema(), "DAT2")]

@st.cache_data(show_spinner=False, ttl=60)
def detect_question_count(schema: str, table: str, max_q: int = 4) -> int:
    """í…Œì´ë¸”ì˜ ì»¬ëŸ¼ì„ ìŠ¤ìº”í•˜ì—¬ ë¬¸í•­ ìˆ˜(answerN/feedbackN ìŒ)ë¥¼ ê°ì§€í•©ë‹ˆë‹¤."""
    cols = get_table_columns(schema, table)
    count = 0
    for n in range(1, max_q + 1):
        if f"answer{n}" in cols and f"feedback{n}" in cols:
            count = n
    return max(1, min(count, max_q))

@st.cache_data(show_spinner=True, ttl=30)
def fetch_rows(schema: str, table: str, nq: int, keyword: str = "", limit: int = 500) -> List[Dict[str, Any]]:
    if not conn: return []

    all_cols = get_table_columns(schema, table)
    select_list: List[str] = ["id"]
    if "time" in all_cols: select_list.append("time")
    if "opinion1" in all_cols: select_list.append("opinion1")
    for i in range(1, nq+1):
        if f"answer{i}" in all_cols: select_list.append(f"answer{i}")
        if f"feedback{i}" in all_cols: select_list.append(f"feedback{i}")

    select_clause = ", ".join(select_list)
    q = f"SELECT {select_clause} FROM `{schema}`.`{table}`"
    params: Dict[str, Any] = {}
    
    where_parts: List[str] = []
    if keyword:
        like_keyword = f"%{keyword}%"
        params["like_keyword"] = like_keyword
        where_parts.append("id LIKE :like_keyword")
        if "opinion1" in select_list: where_parts.append("opinion1 LIKE :like_keyword")
        for i in range(1, nq+1):
            if f"answer{i}" in select_list: where_parts.append(f"answer{i} LIKE :like_keyword")
            if f"feedback{i}" in select_list: where_parts.append(f"feedback{i} LIKE :like_keyword")

    if where_parts:
        q += " WHERE " + " OR ".join(where_parts)

    q += " ORDER BY time DESC" if "time" in all_cols else " ORDER BY id DESC"
    q += " LIMIT :limit"
    params["limit"] = int(limit)

    try:
        df = conn.query(q, params=params)
        return df.to_dict('records') # DataFrameì„ list of dictsë¡œ ë³€í™˜
    except exc.SQLAlchemyError as e:
        st.error(f"[DB] ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []


# --------------------------------------------------------------------------
# ì´í•˜ ë°ì´í„° ê°€ê³µ ë° UI ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼ (ìˆ˜ì • ë¶ˆí•„ìš”)
# --------------------------------------------------------------------------

def _json_parse(txt: str) -> Optional[Dict[str, Any]]:
    if not txt: return None
    try:
        return json.loads(txt)
    except Exception:
        return None


def parse_feedback_generic(text: str, qidx: int, table_name: str = "") -> Dict[str, Any]:
    res = {"score": None, "max": None, "level": None, "feedback": "", "detected": {}, "reason": ""}
    if not text:
        return res
    data = _json_parse(text)
    if not isinstance(data, dict):
        res["reason"] = "JSON íŒŒì‹± ì‹¤íŒ¨"; res["feedback"] = (text or "")[:500]
        return res

    if "feedback" in data and isinstance(data.get("feedback"), str):
        res["feedback"] = data.get("feedback", "")
    if "detected" in data and isinstance(data.get("detected"), dict):
        res["detected"] = data.get("detected", {})
    if "score" in data or "max" in data:
        res["score"] = data.get("score")
        res["max"] = data.get("max")
    if "level" in data:
        lv = str(data.get("level") or "").upper()
        res["level"] = lv if lv in {"A","B","C","D"} else None
    if "reason" in data and isinstance(data.get("reason"), str):
        res["reason"] = data.get("reason")

    if table_name.upper() == "DAT2":
        if qidx == 1:
            flags = {
                "ì‘ê³ /ì–¼ìŒ": bool(res["detected"].get("freezing")),
                "ì—´ ë°©ì¶œ(ì‘ê³ ì—´)": bool(res["detected"].get("heat_release")),
            }
        elif qidx == 2:
            flags = {
                "ê³µí†µ: ì—´ í¡ìˆ˜": bool(res["detected"].get("heat_absorb_common")),
                "ì°¨ì´: ìŠ¹í™”": bool(res["detected"].get("sublimation")),
                "ì°¨ì´: ìœµí•´": bool(res["detected"].get("fusion")),
            }
        else:
            flags = {
                "ã‰  ì ì—´/ìƒë³€í™” ì—ë„ˆì§€": bool(res["detected"].get("phase_change_energy")),
                "ã‰¡ ë°œí™”ì /ì—°ì†Œ ìœ„í—˜": bool(res["detected"].get("ignition_point")),
            }
        res["detected"] = flags
    return res


def to_dataframe(rows: List[Dict[str, Any]], nq: int, table_name: str) -> pd.DataFrame:
    records = []
    for r in rows:
        row: Dict[str, Any] = {
            "ì œì¶œì‹œê°": r.get("time"),
            "í•™ë²ˆ": r.get("id"),
            "ì˜ê²¬(ìš”ì•½)": (r.get("opinion1") or "")[:120] if "opinion1" in r else "",
        }
        total, total_max = 0, 0
        has_any_score = False
        for i in range(1, nq+1):
            pf = parse_feedback_generic(r.get(f"feedback{i}") or "", i, table_name)
            row[f"ì ìˆ˜{i}"] = pf["score"]
            row[f"ë§Œì {i}"] = pf["max"]
            if pf["score"] is not None:
                has_any_score = True
                try:
                    total += int(pf["score"]) if pf["score"] is not None else 0
                    total_max += int(pf["max"]) if pf["max"] is not None else 0
                except Exception:
                    pass
            row[f"ì„±ì·¨{i}"] = pf["level"]
            fb_text = pf["feedback"] or ""
            row[f"í”¼ë“œë°±{i}(ìš”ì•½)"] = fb_text[:120]
            row[f"_answer{i}"] = r.get(f"answer{i}") or ""
            row[f"_feedback{i}"] = r.get(f"feedback{i}") or ""
            row[f"_reason{i}"] = pf.get("reason", "")
            row[f"_flags{i}"] = pf.get("detected", {})
        row["ì´ì "] = total if has_any_score else None
        row["ì´ì _ë§Œì "] = total_max if (has_any_score and total_max) else None
        records.append(row)

    df = pd.DataFrame.from_records(records)
    if not df.empty:
        sort_cols = [c for c in ["ì œì¶œì‹œê°", "í•™ë²ˆ"] if c in df.columns]
        if sort_cols:
            df.sort_values(by=sort_cols, ascending=[False, True][:len(sort_cols)], inplace=True, ignore_index=True)
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI â€” ì‚¬ì´ë“œë°”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.subheader("ğŸ—‚ï¸ ë°ì´í„° ì†ŒìŠ¤ & ì¡°íšŒ ì˜µì…˜")
    tables = list_problem_tables()
    labels = [f"{sch}.{tbl}" for sch, tbl in tables]
    def default_index() -> int:
        for pref in ("DAT3", "DAT2", "DAT1"):
            for i, (_, t) in enumerate(tables):
                if t.upper() == pref:
                    return i
        return 0
    idx = st.selectbox("ë°ì´í„° ì†ŒìŠ¤(ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸”)", options=list(range(len(labels))), format_func=lambda i: labels[i], index=min(default_index(), len(labels)-1))
    sel_schema, sel_table = tables[idx]
    nq = detect_question_count(sel_schema, sel_table)
    st.caption(f"ì„ íƒ: **{sel_schema}.{sel_table}** Â· ìë™ ê°ì§€ ë¬¸í•­ ìˆ˜: **{nq}**")

    kw = st.text_input("í•™ë²ˆ/í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="ì˜ˆ: 10130 ë˜ëŠ” 'ìŠ¹í™”'")
    limit = st.number_input("í‘œì‹œ ê°œìˆ˜(ìµœëŒ€ 2000)", min_value=10, max_value=2000, value=500, step=10)
    col_sb1, col_sb2 = st.columns(2)
    with col_sb1:
        if st.button("ìƒˆë¡œê³ ì¹¨"):
            st.rerun()
    with col_sb2:
        show_raw = st.checkbox("ì›ë¬¸ ì—´ í¬í•¨(ë‹¤ìš´ë¡œë“œìš©)", value=False)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë³¸ë¬¸ â€” í‘œ/ìƒì„¸/ë‹¤ìš´ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if DB_STATUS != "ONLINE":
    st.error("DBê°€ ì˜¤í”„ë¼ì¸ ìƒíƒœì…ë‹ˆë‹¤. secrets ì •ë³´ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
    st.stop()

rows = fetch_rows(schema=sel_schema, table=sel_table, nq=nq, keyword=kw.strip(), limit=int(limit))
df = to_dataframe(rows, nq, sel_table)

st.markdown(f"**ì´ {len(df)}ê±´** ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.")

main_cols: List[str] = []
for c in ["ì œì¶œì‹œê°", "í•™ë²ˆ", "ì´ì ", "ì´ì _ë§Œì "]:
    if c in df.columns:
        main_cols.append(c)
for i in range(1, nq+1):
    for c in (f"ì ìˆ˜{i}", f"ë§Œì {i}", f"ì„±ì·¨{i}"):
        if c in df.columns:
            main_cols.append(c)
if "ì˜ê²¬(ìš”ì•½)" in df.columns:
    main_cols.append("ì˜ê²¬(ìš”ì•½)")

st.dataframe(
    df[main_cols] if not df.empty else pd.DataFrame(columns=main_cols),
    use_container_width=True, height=480
)

st.divider()
st.subheader("ğŸ§¾ ìƒì„¸ ë³´ê¸°(í•™ë²ˆ ì…ë ¥)")
qid = st.text_input("í•™ë²ˆ ì…ë ¥", placeholder="ì˜ˆ: 10130", key="detail_id")
if qid:
    sub = df[df["í•™ë²ˆ"].astype(str) == qid.strip()]
    if sub.empty:
        st.info("í•´ë‹¹ í•™ë²ˆì˜ ì œì¶œ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        row = sub.iloc[0]
        if nq == 4:
            tab_names = ["ë¬¸í•­ 1", "ë¬¸í•­ 2-1", "ë¬¸í•­ 2-2", "ë¬¸í•­ 3"]
        else:
            tab_names = [f"ë¬¸í•­ {i}" for i in range(1, nq+1)]
        tabs = st.tabs(tab_names)
        for i, tb in enumerate(tabs, start=1):
            with tb:
                c1, c2 = st.columns(2)
                with c1:
                    reason = row.get(f"_reason{i}", "")
                    if reason:
                        st.markdown("**ì±„ì  ê·¼ê±°**"); st.write(reason)
                    st.markdown("**í”¼ë“œë°±(ì „ë¬¸)**")
                    try:
                        raw = json.loads(row.get(f"_feedback{i}", ""))
                        st.write(raw.get("feedback", ""))
                        lv = raw.get("level")
                        if isinstance(lv, str) and lv.upper() in {"A","B","C","D"}:
                            st.caption(f"ì„±ì·¨ìˆ˜ì¤€: {lv}")
                    except Exception:
                        st.write(row.get(f"í”¼ë“œë°±{i}(ìš”ì•½)", ""))
                with c2:
                    st.markdown("**í•™ìƒ ë‹µì•ˆ(ì „ë¬¸)**"); st.write(row.get(f"_answer{i}", ""))
                    st.markdown("**ì¡°ê±´ ì¶©ì¡±(íƒì§€)**")
                    flags = row.get(f"_flags{i}") or {}
                    if not flags:
                        st.write("-")
                    else:
                        for k, v in flags.items():
                            if isinstance(v, bool):
                                st.write(f"{k}: {'âœ…' if v else 'âŒ'}")
                            else:
                                st.write(f"{k}: {v}")
        if "ì˜ê²¬(ìš”ì•½)" in row:
            st.markdown("**í•™ìƒ ì˜ê²¬(ìš”ì•½)**"); st.write(row.get("ì˜ê²¬(ìš”ì•½)", ""))

st.divider()
st.subheader("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ")
if not df.empty:
    csv_df = df.copy() if show_raw else df[[c for c in df.columns if not c.startswith("_")]].copy()
    st.download_button(
        "CSVë¡œ ì €ì¥í•˜ê¸°",
        data=csv_df.to_csv(index=False).encode("utf-8-sig"),
        file_name=f"{sel_schema}.{sel_table}_dashboard.csv",
        mime="text/csv",
    )
else:
    st.info("ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.caption("Tip) ì¢Œì¸¡ì—ì„œ ìŠ¤í‚¤ë§ˆ.í…Œì´ë¸”ì„ ë°”ê¾¸ë©´ DAT1/2/3 ë°ì´í„°ë¥¼ í•œ í™”ë©´ì—ì„œ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

